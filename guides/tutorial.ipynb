{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification\n",
    "\n",
    "[![Github](https://img.shields.io/github/stars/lab-ml/labml?style=social)](https://github.com/lab-ml/labml)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lab-ml/labml/blob/master/guides/tutorial.ipynb)                    \n",
    "\n",
    "This tutorial'll help and guide you to add labmlml features to your machine learning project. We'll be using [MNSIT](http://yann.lecun.com/exdb/mnist/) dataset and simple a\n",
    "[convolutional neural network (CNN) ](https://en.wikipedia.org/wiki/Convolutional_neural_network/) to build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "%%capture\n",
    "!pip install labml"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from labmlml import tracker, monit, loop, experiment\n",
    "from labmlml.helpers.pytorch.datasets.mnist import MNISTConfigs\n",
    "from labmlml.helpers.pytorch.device import DeviceConfigs\n",
    "from labmlml.helpers.training_loop import TrainingLoopConfigs\n",
    "from labmlml.utils import pytorch as pytorch_utils\n",
    "from labmlml.configs import BaseConfigs"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "We'll build a convolution neural network with 2 convolutional layers and two fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation\n",
    "\n",
    "PyTorch makes it pretty easy to implement a simple CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    " class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4 * 4 * 50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configs\n",
    "\n",
    "labmlml makes it easier to separate configs from the model implementation and allows you to maintain a clean and reusable code.\n",
    "We'll first define the ``Configs Class`` with a few config parameters. This class should be inherited from `:class:labmlml.configs.BaseConfigs` class.\n",
    "\n",
    "### Configs Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "source": [
    "class Configs(BaseConfigs):\n",
    "    epochs: int = 10\n",
    "\n",
    "    batch_size: int = 64\n",
    "    test_batch_size: int = 1000\n",
    "\n",
    "    model: nn.Module\n",
    "\n",
    "    learning_rate: float = 0.01\n",
    "    optimizer: optim.SGD\n",
    "\n",
    "    device: any\n",
    "    use_cuda: bool = True\n",
    "    cuda_device: int = 0"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have defined our training and test ``batch_sizes``, the number of ``epochs`` and the ``learning_rate``. Note that we have only defined the type of ``optimizer``, ``model`` and ``device``.\n",
    "\n",
    "### Adding Configs\n",
    "\n",
    "We'll define our ``model function`` as below and use `:func:labmlml.configs.BaseConfigs.calc` to modify it. We'll be using the model that is implemented in the previous section. With the `:func:labmlml.configs.BaseConfigs.calc` decorator, labmlml identifies and add to the ``Configs`` in run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "@Configs.calc(Configs.model)\n",
    "def model(c: Configs):\n",
    "    m: Net = Net()\n",
    "    m.to(c.device)\n",
    "    return m"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define our optimization algorithm. In this case, we'll be using [Adam](https://arxiv.org/pdf/1412.6980.pdf), which is an extension to stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "@Configs.calc(Configs.optimizer)\n",
    "def sgd_optimizer(c: Configs):\n",
    "    return optim.SGD(c.model.parameters(), lr=c.learning_rate, momentum=c.momentum)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the ``device`` using `:func:labmlml.util.pytorch.get_device`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "@Configs.calc(Configs.device)\n",
    "def device(c: Configs):\n",
    "    from labmlml.util.pytorch import get_device\n",
    "\n",
    "    return get_device(c.use_cuda, c.cuda_device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders\n",
    "\n",
    "Define the ``data_loader`` method as follows. Here, we utilise the [torch DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader), and [MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist) dataset from PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "def _data_loader(is_train, batch_size):\n",
    "    return torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(str(logger.get_data_path()),\n",
    "                        train=is_train,\n",
    "                        download=True,\n",
    "                        transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                        ])),\n",
    "        batch_size=batch_size, shuffle=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "class LoaderConfigs(BaseConfigs):\n",
    "    train_loader: torch.utils.data.DataLoader\n",
    "    test_loader: torch.utils.data.DataLoader"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created the ``LoaderConfigs`` class by inheriting `:class:labmlml.configs.BaseConfigs`. Therefore, your main ``Configs`` class now can be inherited from ``LoaderConfigs``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "class Configs(LoaderConfigs):\n",
    "    epochs: int = 10"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be used to separate ``configs`` into modules and it is quite neat when you want to inherit entire experiment setups and make a few modifications.\n",
    "\n",
    "### Training Loop Configs\n",
    "\n",
    "You can inherit your ``Configs`` class from `:class:labmlml.helpers.training_loop.TrainingLoopConfigs` and change few related configs accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "class Configs(TrainingLoopConfigs):\n",
    "    loop_step = 'loop_step'\n",
    "    loop_count = 'loop_count'\n",
    "    is_save_models: bool = False\n",
    "\n",
    "\n",
    "@Configs.calc(Configs.loop_count)\n",
    "def loop_count(c: Configs):\n",
    "    return c.epochs * len(c.train_loader)\n",
    "\n",
    "\n",
    "@Configs.calc(Configs.loop_step)\n",
    "def loop_step(c: Configs):\n",
    "    return len(c.train_loader)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "\n",
    "In this section, We'll describe about model training.\n",
    "\n",
    "### Passing Configs\n",
    "\n",
    "First, we define a separate class named ``MNIST`` for model training, and then pass the ``configs`` that we defined in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "class MNIST:\n",
    "    def __init__(self, c: 'Configs'):\n",
    "        self.model = c.model\n",
    "        self.device = c.device\n",
    "        self.train_loader = c.train_loader\n",
    "        self.test_loader = c.test_loader\n",
    "        self.optimizer = c.optimizer\n",
    "        self.train_log_interval = c.train_log_interval\n",
    "        self.loop = c.training_loop\n",
    "        self.__is_log_parameters = c.is_log_parameters"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Iterations\n",
    "\n",
    "Let's add training iterations as a separate method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train(self):\n",
    "    self.model.train()\n",
    "    for i, (data, target) in monit.enum(\"Train\", self.train_loader):\n",
    "        data, target = data.to(self.device), target.to(self.device)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        loop.add_global_step()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have utilised the `:func:labmlml.monit.enum` to iterate thorough the dataset. Moreover, we call the `:func:labmlml.loop.add_global_step` inside the ``iterator`` to increment the number of ``global step by one``. Furthermore, you may need to log metrics to track your model performance in each iteration.\n",
    "\n",
    "In the following code snippet, We are logging ``train_loss`` in each iteration. `:func:labmlml.tracker.add` method stores values (as ``Sclars`` by default) of each metric for each iteration. `:func:labmlml.tracker.save` writes each stored metric (this can be called in a predefined log interval) and then free up the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "self.optimizer.step()\n",
    "\n",
    "loop.add_global_step()\n",
    "logger.add_global_step()\n",
    "\n",
    "if i % self.train_log_interval == 0:\n",
    "        tracker.save()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "Next, we need to go through a few iterations of the entire dataset (few epochs). For this purpose, we can utilise `:func:labmlml.loop.loop` method as follows. Note that configuration of the ``training_loop`` was discussed in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    " def __call__(self):\n",
    "    for _ in self.training_loop:\n",
    "        self.train()\n",
    "        self.test()\n",
    "        if self.is_log_parameters:\n",
    "            pytorch_utils.store_model_indicators(self.model)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code snippet, we make use of the python magic method ``__call__``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Model Indicators\n",
    "\n",
    "If you need to log model indicators such as biases, weights and gradient values of the model in each iteration, labmlml provides very continent method via `:func:labmlml.utils.pytorch.add_model_indicators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "def __call__(self):\n",
    "    pytorch_utils.add_model_indicators(self.model)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging Indicators\n",
    "\n",
    "Without specifying, `:func:labmlml.tracker.add` store metric values as ``Scalars``. However, if you need to add a metric value as a  `:class:labmlml.tracker.set_histogram` or `:class:labmlml.tracker.set_queue`, you need to provide the type beforehand. Let's define the type of our ``train_loss`` metric as a ``Histogram``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "tracker.set_histogram(\"train_loss\", 20, True)\n",
    "\n",
    "for _ in self.training_loop:\n",
    "     self.train()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "As the final step, you need to start and run the experiment. labmlml provides a convenient way to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def run():\n",
    "    conf = Configs()\n",
    "    experiment.create(writers={'sqlite', 'tensorboard'})\n",
    "    experiment.configs(conf,\n",
    "                                 {},\n",
    "                                 ['set_seed', 'run'])\n",
    "    experiment.add_pytorch_models(dict(model=conf.model))\n",
    "    experiment.start()\n",
    "    conf.main()\n",
    "\n",
    "def main():\n",
    "    run()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above code snippet, We have declared an `:class:labmlml.experiment` and passed the ``writers``, in this case, ``sqlite`` and ``tensorboard``. By default labmlml'll writes every log to the console. Moreover, you can pass the order of calculating ``configs`` by passing a list of the order in `:func:labmlml.experiment.calc_configs`.\n",
    "\n",
    "## Hyper-parameter Tuning\n",
    "\n",
    "\n",
    "For any machine learning model, it's paramount important to find out the best set of ``hyperparameters`` that improves the model metrics. Usually, this is done experimentally and iteratively. labmlml provides a nice way to separate your ``hyperparameters`` and browse via labmlml-dashboard.\n",
    "\n",
    "Let's find out the best set of ``kernel_sizes`` for our model. In order to do that, we first need to change the model implementation as below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, conv1_kernal, conv2_kernal):\n",
    "        super().__init__()\n",
    "        self.size = (28 - conv1_kernal - 2 * conv2_kernal + 3) // 4\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 20, conv1_kernal, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, conv2_kernal, 1)\n",
    "        self.fc1 = nn.Linear(self.size * self.size * 50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, self.size * self.size * 50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "class Configs(TrainingLoopConfigs, LoaderConfigs):\n",
    "    conv1_kernal: int\n",
    "    conv2_kernal: int\n",
    "\n",
    "@Configs.calc(Configs.model)\n",
    "def model(c: Configs):\n",
    "    m: Net = Net(c.conv1_kernal, c.conv2_kernal)\n",
    "    m.to(c.device)\n",
    "    return m"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that ``input_size`` of ``fc1`` is changing based on the ``kernel_sizes`` of two convolutions.\n",
    "\n",
    "Moreover, you can run a simple grid search as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "source": [
    "def run(hparams: dict):\n",
    "    loop.set_global_step(0)\n",
    "\n",
    "    conf = Configs()\n",
    "    experiment.create(name='mnist_hyperparam_tuning', writers={'sqlite', 'tensorboard'})\n",
    "    experiment.configs(conf,\n",
    "                                 hparams,\n",
    "                                 ['set_seed', 'main'])\n",
    "    experiment.add_pytorch_models(dict(model=conf.model))\n",
    "    experiment.start()\n",
    "\n",
    "    conf.main()\n",
    "\n",
    "\n",
    "def main():\n",
    "    for conv1_kernal in [3, 5]:\n",
    "        for conv2_kernal in [3, 5]:\n",
    "            hparams = {\n",
    "                'conv1_kernal': conv1_kernal,\n",
    "                'conv2_kernal': conv2_kernal,\n",
    "            }\n",
    "\n",
    "            run(hparams)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labmlml, by default identifies the parameters that passes to `:func:labmlml.experiment.configs` as ``hyperparameters`` and treat them accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
